# Image-Lab

Create an iOS application using the CoreImage template that:

Reads and displays images from the camera in real time
Highlights multiple faces in the scene using CoreImage filters
Highlights eye and mouth position using CoreImage filters
display if the user is smiling or blinking (and with which eye)

Uses video of the user's finger (with flash on) to sense a single dimension stream indicating the "redness" of the finger
Uses the redness to measure the heart rate of the individual (coarse estimate)
